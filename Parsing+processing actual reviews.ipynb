{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook I will:\n",
    "* Parse the reviewer column into actually useful information\n",
    "* Go through and split dataframes based on reviews that have text and those that do not (and save the second to their own file)\n",
    "* Save files with processed reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Haven't decided whether I like nltk or spacy better yet\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "stops = stopwords.words('english')\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "# A method to process text in nltk:\n",
    "# https://pythonhealthcare.org/2018/12/14/101-pre-processing-data-tokenization-stemming-and-removal-of-stop-words/\n",
    "\n",
    "# same process in spacy\n",
    "# https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Just don't have time to learn these right now\n",
    "#from sklearn.base import TransformerMixin\n",
    "#from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting stop words in spacy to not lose a bunch of negatives for the sentiment analysis\n",
    "for word in [u'nor',u'none',u'not',u'alone',u'no',u'never',u'cannot',u'always']:\n",
    "    nlp.vocab[word].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacyTokenizer(s: str)-> list:\n",
    "    doc = nlp(s.lower().strip())\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha and token.lemma_ != '-PRON-':\n",
    "            tokens.append(token.lemma_)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the reviews files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to parse the reviewer information\n",
    "def parse_reviewer(reviewer):\n",
    "    # Find name as unique identifier if present\n",
    "    if reviewer.find(',') != -1:\n",
    "        name = reviewer[reviewer.find(':')+2:reviewer.find(',')]\n",
    "    else:\n",
    "        name = np.NaN\n",
    "    \n",
    "    # Find age range as datapoint if present\n",
    "    if reviewer.find('-') != -1:\n",
    "        if reviewer.find(',') != -1:\n",
    "            age = reviewer[reviewer.find(',')+2:reviewer.find(' ', reviewer.find('-'))]\n",
    "        else:\n",
    "            age = reviewer[reviewer.find(':')+2:reviewer.find(' ', reviewer.find('-'))]\n",
    "    else:\n",
    "        age = np.NaN\n",
    "        \n",
    "    # Find gender if present\n",
    "    if reviewer.find('Male') != -1:\n",
    "        gender = 'Male'\n",
    "    elif reviewer.find('Female') != -1:\n",
    "        gender = 'Female'\n",
    "    else:\n",
    "        gender = np.NaN\n",
    "        \n",
    "    # Find treatment time\n",
    "    if reviewer.find('on Treatment') != -1:\n",
    "        if reviewer.rstrip()[-1] == ')':\n",
    "            treatment_time = reviewer[reviewer.find('on Treatment for ')+16:reviewer.rfind('(')].strip()\n",
    "        else:\n",
    "            treatment_time = reviewer[reviewer.find('on Treatment for ')+16:].rstrip().strip()\n",
    "    else:\n",
    "        treatment_time = np.NaN\n",
    "    \n",
    "    # Put info in a dictionary that can be made into a dictionary\n",
    "    reviewer_info = {}\n",
    "    reviewer_info['Name'] = name\n",
    "    reviewer_info['Age'] = age\n",
    "    reviewer_info['Gender'] = gender\n",
    "    reviewer_info['Length of treatment'] = treatment_time\n",
    "    \n",
    "    return reviewer_info\n",
    "\n",
    "def processReviewerColumn(reviewDF):\n",
    "    # Parse the reviewer info\n",
    "    reviewers = []\n",
    "    for reviewer in reviewDF['reviewer']:\n",
    "        reviewers.append(parse_reviewer(reviewer))\n",
    "    reviewersDF = pd.DataFrame(reviewers, index=reviewDF.index)\n",
    "\n",
    "    # Drop the reviewer column from the original dataframe\n",
    "    reviewDF = reviewDF.drop(columns=['reviewer'])\n",
    "\n",
    "    # Add the parsed reviewer info to the original dataframe\n",
    "    reviewDF = pd.concat([reviewDF, reviewersDF], axis=1)\n",
    "    \n",
    "    return reviewDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def compare_parsedAndEmpty(parsed,empty,file):\n",
    "    # Making a graph to compare the populations\n",
    "    fig, ax = plt.subplots(1,2,constrained_layout='True', figsize=(15,5))\n",
    "    parsed.hist(column='Satisfaction', color='skyblue', ax=ax[0], bins = np.arange(0.75,5.5,0.5),\n",
    "                  density=True, label='With comment')\n",
    "    empty.hist(column='Satisfaction', color='orange', ax=ax[0], bins = np.arange(0.75,5.5,0.5),\n",
    "                      density=True, alpha=0.5, label='No comment')\n",
    "    ax[0].set_title('Satisfaction  (Empty: {:g}/{:g})'.format(len(empty), (len(empty)+len(parsed))))\n",
    "    ax[0].legend(loc='best')\n",
    "    ax[0].set_xlabel('Number of stars')\n",
    "    ax[0].set_ylabel('% of reviews')\n",
    "\n",
    "    parsed.hist(column='Effectiveness', color='skyblue', bins = np.arange(0.75,5.5,0.5),\n",
    "                  ax=ax[1], density=True, label='With comment')\n",
    "    empty.hist(column='Effectiveness', color='orange', bins = np.arange(0.75,5.5,0.5),\n",
    "                      ax=ax[1], density=True, alpha=0.5, label='No comment')\n",
    "    ax[1].set_title('Satisfaction  (Empty: {:g}/{:g})'.format(len(empty), (len(empty)+len(parsed))))\n",
    "    ax[1].legend(loc='best')\n",
    "    ax[1].set_xlabel('Number of stars')\n",
    "    ax[1].set_ylabel('% of reviews')\n",
    "    \n",
    "    directory = file[:file.rfind('/')+1] + 'plots/'\n",
    "    if not glob.glob(directory+'*.png'):\n",
    "        os.mkdir(directory)\n",
    "        \n",
    "    savefile = file[file.rfind('/')+1:].replace('raw_reviews.csv','empty_compare.png')\n",
    "    fig.savefig(directory+savefile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing all the files I need to process\n",
    "files = glob.glob('ProcessedReviews/*/*raw_reviews.csv')\n",
    "files = [file for file in files if file.find('allconditions') == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing all the files\n",
    "for file in files:\n",
    "    # Reading in file\n",
    "    df = pd.read_csv(file, sep='$', index_col=0)\n",
    "\n",
    "    # Reseting index to remove the indices that were split by condition separation\n",
    "    # Dropping that index column\n",
    "    df = df.reset_index().drop(columns=['index'])\n",
    "\n",
    "    # Dropping comments that contain no information\n",
    "    parsedDF = processReviewerColumn(df).dropna(subset=['Comment'])\n",
    "    parsedDF.to_csv(file.replace('raw','parsed'), sep='$')\n",
    "    \n",
    "    # Finding the empty reviews and making them a dataframe\n",
    "    emptyReviews = pd.DataFrame([df.loc[ind] for ind in df.index if ind not in parsedDF.index])\n",
    "    if emptyReviews.any().any():\n",
    "        emptyReviews.to_csv(file.replace('raw','empty'),sep='$')\n",
    "    \n",
    "        # Creating some plots to review later\n",
    "        compare_parsedAndEmpty(parsedDF, emptyReviews, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
