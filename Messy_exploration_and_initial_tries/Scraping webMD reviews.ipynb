{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and creating a distinct file to make scraping separate from altering the metadata file (Medications_SideEffects_BrandsAndLinks.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing original medications/SE dataframe\n",
    "def makeListofStr(s: str) -> list:\n",
    "    List = s[1:-1].split(\"'\")\n",
    "    List = [string for string in List if string and string != ', ']\n",
    "    return List\n",
    "\n",
    "medsDF = pd.read_csv('Medications_SideEffects_brandAndlinks.csv', index_col=0,\n",
    "                    converters={'Parent links': lambda x: makeListofStr(x), 'Exact medications': lambda x: makeListofStr(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_review(userPost, revnum=1):\n",
    "    info = {}\n",
    "    \n",
    "    # Pulling basic post info\n",
    "    info['conditionInfo'] = userPost.find('div', attrs={'class':'conditionInfo'}).text.replace('\\r\\n\\t\\t\\t\\t\\t','')\n",
    "    info['date'] = userPost.find('div', attrs={'class':'date'}).text\n",
    "    info['reviewer'] = userPost.find('p', attrs={'class':'reviewerInfo'}).text\n",
    "    \n",
    "    # Pulling stars info\n",
    "    content = userPost.find('div', attrs={'id':'ctnStars'})\n",
    "    catsAndScores = []\n",
    "    for child in content.findChildren():\n",
    "        nextisScore=False\n",
    "        for grandChild in child.findChildren():\n",
    "            if nextisScore:\n",
    "                score = grandChild.find('span', attrs={'class':'current-rating'}).text\n",
    "                score = score[score.rfind(' ')+1:]\n",
    "                catsAndScores.append((category, score))\n",
    "                nextisScore=False\n",
    "            if str(grandChild).find('category') != -1:\n",
    "                category = str(grandChild)\n",
    "                category = category[category.find('gory\">')+6:category.rfind('</p>')]\n",
    "                nextisScore=True\n",
    "    catsAndScores = dict(catsAndScores)\n",
    "    info['Effectiveness'] = catsAndScores['Effectiveness']\n",
    "    info['Satisfaction'] = catsAndScores['Satisfaction']\n",
    "    info['Ease of Use'] = catsAndScores['Ease of Use']\n",
    "    \n",
    "    # Pulling comment and cleaning it up\n",
    "    text = userPost.find('p', attrs={'style':'display:none',\n",
    "                                     'id':'comFull{:g}'.format(revnum)}).text\n",
    "    text = text.replace('<strong>Comment:</strong>','').replace('<br','')\n",
    "    text = text.replace('Hide Full Comment', '').replace('Comment:','')\n",
    "    info['Comment'] = text\n",
    "    \n",
    "    return info\n",
    "\n",
    "def proceed2NextPage(url):\n",
    "    num = int(url[url.find('pageIndex=')+10:url.rfind('&sortby')])\n",
    "    newurl = url.replace('pageIndex={:g}'.format(num),\n",
    "                         'pageIndex={:g}'.format(num+1))\n",
    "    return newurl\n",
    "\n",
    "def scrollReviews(reviewPage0, reviewsPerPage=5):\n",
    "    # Going to the reviews page and finding the total number of reviews\n",
    "    response = requests.get(reviewPage0)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    content = soup.find('span', attrs={'class':'totalreviews'})\n",
    "    if not content: # In case there are no reviews\n",
    "        return None\n",
    "    totalreviews = content.text\n",
    "    totalreviews = totalreviews[:totalreviews.rfind('Total')-1]\n",
    "\n",
    "    # Counting the number of pages\n",
    "    totalreviews = int(totalreviews)\n",
    "    num_pages = totalreviews // reviewsPerPage\n",
    "    if totalreviews % reviewsPerPage: num_pages += 1\n",
    "    \n",
    "    # Iterating through pages and grabbing review data\n",
    "    all_reviews = []\n",
    "    for npage in range(num_pages):\n",
    "        # Finding the relevant page\n",
    "        if npage == 0:\n",
    "            url = reviewPage0\n",
    "        else:\n",
    "            url = proceed2NextPage(url)\n",
    "    \n",
    "        # Get heading above userPosts\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        content = soup.find('div', attrs={'id':'ratings_fmt'})\n",
    "    \n",
    "        revnum = 1\n",
    "        for child in content.findChildren():\n",
    "            if str(child).find('userPost') != -1:\n",
    "                child_info = pull_review(child, revnum=revnum)\n",
    "                all_reviews.append(child_info)\n",
    "                revnum += 1\n",
    "            \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    # Process list all_reviews into dataframe and return\n",
    "    return pd.DataFrame(all_reviews)\n",
    "        \n",
    "        \n",
    "def getReviewsLink(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    content = soup.find('div', attrs={'class':'drug-review-lowest'})\n",
    "    if content:\n",
    "        searchLink = ''\n",
    "        for child in content.findChildren():\n",
    "            if str(child).find('\"drug-review\"') != -1:\n",
    "                searchLink = str(child)\n",
    "                searchLink = searchLink[searchLink.find('href=\"')+6:searchLink.rfind('\">')]\n",
    "                searchLink += '&pageIndex=0&sortby=3&conditionFilter=-1' # grabs reviews for every condition\n",
    "                searchLink = 'https://www.webmd.com'+searchLink\n",
    "                break\n",
    "            \n",
    "        return searchLink\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def formatExactMed(s: str)->str:\n",
    "    s = s.strip() # remove preceding and trailing white space\n",
    "    s=s.replace(',','-') # Get rid of commas\n",
    "    s=s.replace(' ', '-') # Get rid of white space\n",
    "    s=s.replace('/', 'per') # remove things that make it look like a path\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes WebMD and pulls review for every medication it can\n",
    "for ind, medication in zip(medsDF.index,medsDF['Medication']):\n",
    "    for link, exactMed in zip(medsDF.loc[ind]['Parent links'], medsDF.loc[ind]['Exact medications']):\n",
    "        if not glob.glob('Reviews/{:s}_reviews.csv'.format(formatExactMed(exactMed))):\n",
    "            reviewLink = getReviewsLink(link)\n",
    "        else:\n",
    "            reviewLink = None\n",
    "\n",
    "        if reviewLink:\n",
    "            reviewsDF = scrollReviews(reviewLink)\n",
    "            if type(reviewsDF) != type(None):\n",
    "                reviewsDF.to_csv('Reviews/{:s}_reviews.csv'.format(formatExactMed(exactMed)), sep='$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
