{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "stops = stopwords.words('english')\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Must process medsDF file to include info on brand name meds, in NLP, track number of tries by medication mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the names into numbers...hashing of some kind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing original medications/SE dataframe\n",
    "def makeListofStr(s: str) -> list:\n",
    "    List = s[1:-1].split(\"'\")\n",
    "    List = [string for string in List if string and string != ', ']\n",
    "    return List\n",
    "\n",
    "medsDF = pd.read_csv('Medications_SideEffects_brandAndlinks.csv', index_col=0,\n",
    "                    converters={'Parent links': lambda x: makeListofStr(x), 'Exact medications': lambda x: makeListofStr(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making it possible to grab the files in Reviews/\n",
    "def formatExactMed(s: str)->str:\n",
    "    s = s.strip() # remove preceding and trailing white space\n",
    "    s=s.replace(',','-') # Get rid of commas\n",
    "    s=s.replace(' ', '-') # Get rid of white space\n",
    "    s=s.replace('/', 'per') # remove things that make it look like a path\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering all the files into one dictionary related to the associated medication\n",
    "allfiles = []\n",
    "for ind, medication in zip(medsDF.index, medsDF['Medication']):\n",
    "    files = list(set([glob.glob('Reviews/'+formatExactMed(exactMed)+'_reviews.csv')[0] for exactMed in medsDF.loc[ind]['Exact medications'] if glob.glob('Reviews/'+formatExactMed(exactMed)+'_reviews.csv')]))\n",
    "    files += list(set([glob.glob('Reviews/'+formatExactMed(exactMed).lower()+'_reviews.csv')[0] for exactMed in medsDF.loc[ind]['Exact medications'] if glob.glob('Reviews/'+formatExactMed(exactMed).lower()+'_reviews.csv')]))\n",
    "    allfiles.append((medication, files))\n",
    "allfiles = dict(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all the hormone patches from Daytrana's results:\n",
    "allfiles['Daytrana transdermal'] = ['Reviews/Daytrana-Patch--Transdermal-24-Hours_reviews.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping together medications by all of their alternate names (allowing for access by brandnames or generics)\n",
    "for ind, altnames in zip(medsDF.index, medsDF['Alternate names']):\n",
    "    if type(altnames) != float:\n",
    "        stack = []\n",
    "        for name in [altnames.split(', ')+[medsDF.loc[ind]['Medication']]][0]:\n",
    "            #if name in allfiles.keys() # Can't use this because if it's part of the word of a key, it includes it\n",
    "            for key in allfiles.keys():\n",
    "                if name == key: \n",
    "                    stack += allfiles[name]\n",
    "        for name in [altnames.split(', ')+[medsDF.loc[ind]['Medication']]][0]:\n",
    "            for key in allfiles.keys():\n",
    "                if name == key:\n",
    "                    allfiles[name] = stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing up weird error I can't figure out for the life of me\n",
    "# Error is that amphetamine is sneaking into dextroamphetamine box...despite the two strings not being equivalent\n",
    "copy = allfiles['Dextroamphetamine '].copy()\n",
    "for item in allfiles['Dextroamphetamine ']:\n",
    "    if (item.lower().find('adderall') != -1 or item.lower().find('amphet') != -1) and item.find('oamphetamine') == -1:\n",
    "        copy.remove(item)\n",
    "    elif item.lower().find('dextroamphetamine-amphet') != -1:\n",
    "        copy.remove(item)\n",
    "        \n",
    "copy = allfiles['Adderall'].copy()\n",
    "for item in allfiles['Adderall']:\n",
    "    if (item.lower().find('dextroamphetamine') != -1 or item.lower().find('dexedrine') != -1):\n",
    "        copy.remove(item)\n",
    "        \n",
    "allfiles['Dextroamphetamine '] = copy\n",
    "allfiles['Adderall'] = copy\n",
    "allfiles['Amphetamine '].remove('Reviews/dextroamphetamine-amphetamine_reviews.csv')\n",
    "allfiles['Evekeo'].remove('Reviews/dextroamphetamine-amphetamine_reviews.csv')\n",
    "allfiles['Adderall'] = allfiles['Evekeo'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with cases where there are keys that are capitalized or lowercase\n",
    "lowkeys = [key for key in allfiles.keys() if key == key.lower()]\n",
    "capkeys = [key for key in allfiles.keys() if key == key.capitalize()]\n",
    "\n",
    "for lowkey in lowkeys:\n",
    "    # Finding all matching capital and lowercase keys\n",
    "    for capkey in capkeys:\n",
    "        if capkey.lower() == lowkey:\n",
    "            allfiles[capkey] = list(set(allfiles[capkey]) | set(allfiles[lowkey]))\n",
    "            allfiles.pop(lowkey)\n",
    "    # if lowkey still in the dictionary, capitalizing it...yes\n",
    "    if lowkey in allfiles.keys():\n",
    "        allfiles[lowkey.capitalize()] = allfiles[lowkey].copy()\n",
    "        allfiles.pop(lowkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking all the relevant files and stacking them into a single dataframe, then saving before further processing    \n",
    "for medication in allfiles:\n",
    "    for i, file in enumerate(allfiles[medication]):\n",
    "        if file and i == 0:\n",
    "            stackDF = pd.read_csv(file, sep='$', index_col=0, skip_blank_lines=False)\n",
    "        else:\n",
    "            stackDF = stackDF.append(pd.read_csv(file, sep='$', index_col=0, skip_blank_lines=False), ignore_index=True, sort=False)\n",
    "        \n",
    "        # Removing duplicate entries\n",
    "        stackDF = stackDF.drop_duplicates()\n",
    "        \n",
    "        # Writing to a CSV file\n",
    "        stackDF.to_csv('ProcessedReviews/{:s}_allconditions_raw_reviews.csv'.format(medication.strip().replace(' ','-')), sep='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing all the information on conditions\n",
    "conditions = []\n",
    "for medication in allfiles:\n",
    "    if allfiles[medication]:\n",
    "        file = 'ProcessedReviews/{:s}_allconditions_raw_reviews.csv'.format(medication.strip().replace(' ','-'))\n",
    "        conditions.append(np.unique(pd.read_csv(file, sep='$', index_col=0, skip_blank_lines=False)['conditionInfo']))\n",
    "        \n",
    "conditions = np.unique(np.hstack(conditions))\n",
    "conditions = [cond[cond.find(': ')+2:] for cond in conditions if cond != 'Condition: ']\n",
    "\n",
    "origConditions = [cond.replace('-',' ') for cond in np.unique(medsDF['Condition'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, writing actual code to process the conditions\n",
    "# NLTK treats capital nouns as proper nouns! That's why it's not working!\n",
    "\n",
    "def process_condition_string(s: str) -> list:\n",
    "    # Breaking into words\n",
    "    words = nltk.word_tokenize(s)\n",
    "    \n",
    "    # Managing frustrating formatting of certain conditions\n",
    "    words = [word.replace('-',' ').split(' ') for word in words]\n",
    "    newwords = []\n",
    "    for word in words: \n",
    "        if type(word) == str:\n",
    "            newwords.append(word)\n",
    "        elif type(word) == list:\n",
    "            newwords += word\n",
    "    words = newwords\n",
    "    \n",
    "    # Breaking the words into stems\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmaed_words = [lemmatizer.lemmatize(word.lower(),'n') for word in words]\n",
    "\n",
    "    # Removing stop words\n",
    "    goWords = [word.lower() for word in lemmaed_words if word not in stops and word.isalpha()]\n",
    "    \n",
    "    return goWords\n",
    "\n",
    "def process_original_conditions(s: str) -> list:\n",
    "    # Breaking into words\n",
    "    words = nltk.word_tokenize(s)\n",
    "    \n",
    "    # Breaking the words into stems\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmaed_words = [lemmatizer.lemmatize(word.lower(),'n') for word in words]\n",
    "    \n",
    "    # Adding in some terms relevant to particular conditions\n",
    "    if 'bipolar' in lemmaed_words:\n",
    "        lemmaed_words += ['manic', 'mania']\n",
    "        lemmaed_words.remove('disorder')\n",
    "    elif 'adhd' in lemmaed_words:\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets('ADHD'):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name().replace('_', ' '))\n",
    "        synonyms = list(np.unique(synonyms))\n",
    "        synonyms = [[lemmatizer.lemmatize(word.lower(),'n') for word in syn.split(' ')] for syn in synonyms]\n",
    "        synonyms = list(np.hstack(synonyms))\n",
    "        lemmaed_words += list(set(synonyms))\n",
    "#         lemmaed_words += ['attention', 'deficit disorder hyperactivity']\n",
    "        lemmaed_words.remove('disorder')\n",
    "    elif 'depression' in lemmaed_words:\n",
    "        lemmaed_words += ['depressive','depressed']\n",
    "    elif 'anxiety' in lemmaed_words:\n",
    "        lemmaed_words += [lemmatizer.lemmatize(word) for word in ['anxious', 'anxiousness']]\n",
    "    elif 'schizophrenia' in lemmaed_words:\n",
    "        lemmaed_words += ['schizoaffective']\n",
    "        \n",
    "    # Dropping everything into lowercase\n",
    "    lemmaed_words = [word.lower() for word in lemmaed_words]\n",
    "    \n",
    "    return lemmaed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed words for matching\n",
    "processedOrig = [(orig, process_original_conditions(orig)) for orig in origConditions]\n",
    "processedConds = [(cond, process_condition_string(cond)) for cond in conditions]\n",
    "processedConds = dict(processedConds) # Making a dictionary to iterate through\n",
    "processedOrig = dict(processedOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split review conditions into buckets of \"keep\" and \"drop\", based on relevance\n",
    "keep = {}\n",
    "for orig in processedOrig: keep[orig] = []\n",
    "drop = []\n",
    "for cond in processedConds:\n",
    "    check = []\n",
    "    for orig in processedOrig:\n",
    "        test = list(set([orig for c in processedConds[cond] if c in processedOrig[orig]]))\n",
    "        if test:\n",
    "            check.append(test[0])\n",
    "    for c in check:\n",
    "        if c:\n",
    "            keep[c].append(cond)\n",
    "    if c not in keep.values(): drop.append(cond)\n",
    "        \n",
    "# Removing repeat items that arise due to imperfections in the above process\n",
    "for orig in processedOrig:\n",
    "    for item in keep[orig]:\n",
    "        if item in drop: drop.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADHD': ['Attention Deficit Disorder with Hyperactivity'],\n",
       " 'Anxiety': ['Anxiety associated with an Operation',\n",
       "  'Anxious',\n",
       "  'Anxiousness associated with Depression',\n",
       "  'Repeated Episodes of Anxiety',\n",
       "  'Sleep Disturbance with Extreme Anxiety'],\n",
       " 'Bipolar Disorder': ['Agitation associated with Bipolar Mania',\n",
       "  'Bipolar Depression',\n",
       "  'Bipolar Disorder in Remission',\n",
       "  'Bipolar I Disorder with Most Recent Episode Mixed',\n",
       "  'Depression associated with Bipolar Disorder, Adjunct Treatment',\n",
       "  'Mania associated with Bipolar Disorder',\n",
       "  'Mania associated with Bipolar Disorder, Adjunct Treatment',\n",
       "  'Manic-Depression',\n",
       "  'Rapid Cycle Manic-Depression'],\n",
       " 'Depression': ['Additional Medications to Treat Depression',\n",
       "  'Anxiousness associated with Depression',\n",
       "  'Depressed Mood Disorder Occurring Every Year at the Same Time',\n",
       "  'Depression',\n",
       "  'Depression following Delivery of Baby',\n",
       "  'Major Depressive Disorder'],\n",
       " 'Schizophrenia': ['Agitation associated with Schizophrenia',\n",
       "  'Chronic Type of Schizophrenia',\n",
       "  'Schizophrenia',\n",
       "  'Schizophrenia With Mood Changes',\n",
       "  'Suicidal Behavior in Schizoaffective Disorder',\n",
       "  'Treatment-Resistant Schizophrenia']}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning up adhd and depression:\n",
    "keep['ADHD'] = ['Attention Deficit Disorder with Hyperactivity']\n",
    "depKeeps = keep['Depression'].copy()\n",
    "for item in keep['Depression']:\n",
    "    if item.lower().find('bipolar') != -1: \n",
    "        depKeeps.remove(item)\n",
    "    elif item.lower().find('manic') != -1:\n",
    "        depKeeps.remove(item)\n",
    "keep['Depression'] = depKeeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADHD': ['Attention Deficit Disorder with Hyperactivity'],\n",
       " 'Anxiety': ['Anxiety associated with an Operation',\n",
       "  'Anxious',\n",
       "  'Anxiousness associated with Depression',\n",
       "  'Repeated Episodes of Anxiety',\n",
       "  'Sleep Disturbance with Extreme Anxiety'],\n",
       " 'Bipolar Disorder': ['Agitation associated with Bipolar Mania',\n",
       "  'Bipolar Depression',\n",
       "  'Bipolar Disorder in Remission',\n",
       "  'Bipolar I Disorder with Most Recent Episode Mixed',\n",
       "  'Depression associated with Bipolar Disorder, Adjunct Treatment',\n",
       "  'Mania associated with Bipolar Disorder',\n",
       "  'Mania associated with Bipolar Disorder, Adjunct Treatment',\n",
       "  'Manic-Depression',\n",
       "  'Rapid Cycle Manic-Depression'],\n",
       " 'Depression': ['Additional Medications to Treat Depression',\n",
       "  'Anxiousness associated with Depression',\n",
       "  'Depressed Mood Disorder Occurring Every Year at the Same Time',\n",
       "  'Depression',\n",
       "  'Depression following Delivery of Baby',\n",
       "  'Major Depressive Disorder'],\n",
       " 'Schizophrenia': ['Agitation associated with Schizophrenia',\n",
       "  'Chronic Type of Schizophrenia',\n",
       "  'Schizophrenia',\n",
       "  'Schizophrenia With Mood Changes',\n",
       "  'Suicidal Behavior in Schizoaffective Disorder',\n",
       "  'Treatment-Resistant Schizophrenia']}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split by conditions\n",
    "# Need to remove all reviews with no comment info\n",
    "# Need to process the comments\n",
    "# Need to process the review info\n",
    "\n",
    "# Need to strategize on NLP stuff T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing code to sort dataframe into different conditions\n",
    "def splitDFbyCondition(file, condDict, condColumn='conditionInfo'):\n",
    "    # Reading in file and cleaning up condition column if contains extraneous text\n",
    "    df = pd.read_csv(file, sep='$', index_col=0)\n",
    "    procCond = list(df['conditionInfo'])\n",
    "    procCond = [cond.replace('Condition: ','') for cond in procCond]\n",
    "    df['conditionInfo'] = procCond\n",
    "    \n",
    "    # Finding all the conditions for each file and gathering relevant indices\n",
    "    splitDFs = []\n",
    "    for key in condDict:\n",
    "        condIndices = []\n",
    "        for condition in condDict[key]:\n",
    "            for ind, dfCond in zip(df.index, df[condColumn]):\n",
    "                if dfCond == condition: condIndices.append(ind)\n",
    "        splitDFs.append((key, condIndices))\n",
    "    splitDFs = dict(splitDFs)\n",
    "    \n",
    "    for key in splitDFs:\n",
    "        name = key.replace(' ','-')\n",
    "        newDF = pd.DataFrame([df.loc[ind] for ind in splitDFs[key]])\n",
    "        if newDF.any().any(): # Making sure there's actually data\n",
    "            newDF.to_csv(file.replace('raw', name+'_raw').replace('allconditions_',''), sep='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "for medication in allfiles:\n",
    "    if allfiles[medication]:\n",
    "        file = 'ProcessedReviews/{:s}_allconditions_raw_reviews.csv'.format(medication.strip().replace(' ','-'))\n",
    "        splitDFbyCondition(file, keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final files saved in last step have no duplicate rows and are sorted by condition (and have no conditions I'm not considering in this work)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
