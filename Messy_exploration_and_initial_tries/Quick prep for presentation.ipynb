{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet#, stopwords\n",
    "#stops = stopwords.words('english')\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13928155/spell-checker-for-python/48280566\n",
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not super useful to take the mean across columns, instead look at top 10 scoring words in each side effect\n",
    "def findTop(strList, keeptop=10):\n",
    "    tfidf_vectr = TfidfVectorizer()\n",
    "    corpus = [' '.join(SE) for SE in strList]\n",
    "    tfidf_score = tfidf_vectr.fit_transform(corpus).toarray()\n",
    "    features = np.array(tfidf_vectr.get_feature_names())\n",
    "    \n",
    "    words = []\n",
    "    for row in tfidf_score:\n",
    "        inds = row.argsort()[::-1][:keeptop]\n",
    "        row_words = []\n",
    "        for ind in inds:\n",
    "            if row[ind] != 0:\n",
    "                row_words.append(features[ind])\n",
    "                #print(features[ind],' '*(50-len(features[ind])), row[ind].round(2))\n",
    "        #print('\\n')\n",
    "        if not row_words:\n",
    "            row_words = list(features[inds][:5])\n",
    "        words.append(row_words)\n",
    "    return tfidf_score, words\n",
    "\n",
    "# Magic tokenizer thing\n",
    "def spacyTokenizer(s: str)-> list:\n",
    "    doc = tokenizer(s.lower().strip())\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha and token.lemma_ != '-PRON-':\n",
    "            tokens.append(token.lemma_)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "def parseRevnew(review):\n",
    "    reviews = [review]\n",
    "    clean_reviews = [spacyTokenizer(rev.replace('/', ' ')) for rev in reviews]\n",
    "    feat_weights, clean_rev = findTop(clean_reviews, 50)\n",
    "    cleaner_reviews = [[spell(word.lower()) for word in rev] for rev in clean_rev]\n",
    "    \n",
    "    return feat_weights, cleaner_reviews#consider, ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, words = parseRevnew(\"...I'm hoping this really wierd drowzy/tired/sleepy/no motivation/no energy/no emotions/blah/netflix-binge mood is not how this medicine will make me feel for very lon. I didn't really notice any effects at 25mgs, but today, my first day on 50mgs has been rough. Had a panic attack earlier and then settled into this mood. Blllaaaahahhhhhhhh. :-/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wierd feel blah day drowsy early effect emotion energy hope tire medicine mood motivation notice panic settle sleepy attack'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(words[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not super useful to take the mean across columns, instead look at top 10 scoring words in each side effect\n",
    "def findTop(strList, keeptop=10):\n",
    "    tfidf_vectr = TfidfVectorizer()\n",
    "    corpus = [' '.join(SE) for SE in strList]\n",
    "    tfidf_score = tfidf_vectr.fit_transform(corpus).toarray()\n",
    "    features = np.array(tfidf_vectr.get_feature_names())\n",
    "    \n",
    "    words = []\n",
    "    for row in tfidf_score:\n",
    "        inds = row.argsort()[::-1][:keeptop]\n",
    "        row_words = []\n",
    "        for ind in inds:\n",
    "            if row[ind] != 0:\n",
    "                row_words.append(features[ind])\n",
    "                #print(features[ind],' '*(50-len(features[ind])), row[ind].round(2))\n",
    "        #print('\\n')\n",
    "        if not row_words:\n",
    "            row_words = list(features[inds][:5])\n",
    "        words.append(row_words)\n",
    "    return tfidf_score, words\n",
    "\n",
    "# Magic tokenizer thing\n",
    "def spacyTokenizer(s: str)-> list:\n",
    "    doc = tokenizer(s.lower().strip())\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha and token.lemma_ != '-PRON-':\n",
    "            tokens.append(token.lemma_)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "def parseRevnew(review):\n",
    "    reviews = [review]\n",
    "    clean_reviews = [spacyTokenizer(rev.replace('/', ' ')) for rev in reviews]\n",
    "    feat_weights, clean_rev = findTop(clean_reviews, 50)\n",
    "    cleaner_reviews = [[spell(word.lower()) for word in rev] for rev in clean_rev]\n",
    "    \n",
    "    return feat_weights, cleaner_reviews#consider, ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
